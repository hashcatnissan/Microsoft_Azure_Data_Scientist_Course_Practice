{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Defining a search space**"
      ],
      "metadata": {
        "id": "3EKLbHRgiIER"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KjBEjCjiGAl"
      },
      "outputs": [],
      "source": [
        "from azureml.train.hyperdrive import choice, normal\n",
        "\n",
        "param_space = {\n",
        "                 '--batch_size': choice(16, 32, 64),\n",
        "                 '--learning_rate': normal(10, 3)\n",
        "              }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grid sampling**"
      ],
      "metadata": {
        "id": "5Hsq3ANAiRkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.hyperdrive import GridParameterSampling, choice\n",
        "\n",
        "param_space = {\n",
        "                 '--batch_size': choice(16, 32, 64),\n",
        "                 '--learning_rate': choice(0.01, 0.1, 1.0)\n",
        "              }\n",
        "\n",
        "param_sampling = GridParameterSampling(param_space)"
      ],
      "metadata": {
        "id": "PJTK41gjiOfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random sampling**"
      ],
      "metadata": {
        "id": "N5aKYABkiU5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.hyperdrive import RandomParameterSampling, choice, normal\n",
        "\n",
        "param_space = {\n",
        "                 '--batch_size': choice(16, 32, 64),\n",
        "                 '--learning_rate': normal(10, 3)\n",
        "              }\n",
        "\n",
        "param_sampling = RandomParameterSampling(param_space)"
      ],
      "metadata": {
        "id": "5HebHerwiX6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bayesian sampling**"
      ],
      "metadata": {
        "id": "MY3h1lM2iaOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.hyperdrive import BayesianParameterSampling, choice, uniform\n",
        "\n",
        "param_space = {\n",
        "                 '--batch_size': choice(16, 32, 64),\n",
        "                 '--learning_rate': uniform(0.05, 0.1)\n",
        "              }\n",
        "\n",
        "param_sampling = BayesianParameterSampling(param_space)"
      ],
      "metadata": {
        "id": "CxiNOX0SidCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bandit policy**"
      ],
      "metadata": {
        "id": "hDYaUI5Lif3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.hyperdrive import BanditPolicy\n",
        "\n",
        "early_termination_policy = BanditPolicy(slack_amount = 0.2,\n",
        "                                        evaluation_interval=1,\n",
        "                                        delay_evaluation=5)"
      ],
      "metadata": {
        "id": "VlBlEzjOijul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Median stopping policy**"
      ],
      "metadata": {
        "id": "pDRKJeR0jEYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.hyperdrive import MedianStoppingPolicy\n",
        "\n",
        "early_termination_policy = MedianStoppingPolicy(evaluation_interval=1,\n",
        "                                                delay_evaluation=5)"
      ],
      "metadata": {
        "id": "BWUQPrj6jGCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Truncation selection policy**"
      ],
      "metadata": {
        "id": "89Yu6TwujHyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.hyperdrive import TruncationSelectionPolicy\n",
        "\n",
        "early_termination_policy = TruncationSelectionPolicy(truncation_percentage=10,\n",
        "                                                     evaluation_interval=1,\n",
        "                                                     delay_evaluation=5)"
      ],
      "metadata": {
        "id": "2QE9rKXrjKXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running a hyperparameter tuning experiment**"
      ],
      "metadata": {
        "id": "b2Ym8iY8sSDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a training script for hyperparameter tuning**"
      ],
      "metadata": {
        "id": "xf9ZIPLet-PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import joblib\n",
        "from azureml.core import Run\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Get regularization hyperparameter\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01)\n",
        "args = parser.parse_args()\n",
        "reg = args.reg_rate\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# load the training dataset\n",
        "data = run.input_datasets['training_data'].to_pandas_dataframe()\n",
        "\n",
        "# Separate features and labels, and split for training/validatiom\n",
        "X = data[['feature1','feature2','feature3','feature4']].values\n",
        "y = data['label'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
        "\n",
        "# Train a logistic regression model with the reg hyperparameter\n",
        "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "# calculate and log accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# Save the trained model\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "joblib.dump(value=model, filename='outputs/model.pkl')\n",
        "\n",
        "run.complete()"
      ],
      "metadata": {
        "id": "IrYnK1GHt5DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configuring and running a hyperdrive experiment**"
      ],
      "metadata": {
        "id": "XOa29iMauDHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.train.hyperdrive import HyperDriveConfig, PrimaryMetricGoal\n",
        "\n",
        "# Assumes ws, script_config and param_sampling are already defined\n",
        "\n",
        "hyperdrive = HyperDriveConfig(run_config=script_config,\n",
        "                              hyperparameter_sampling=param_sampling,\n",
        "                              policy=None,\n",
        "                              primary_metric_name='Accuracy',\n",
        "                              primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                              max_total_runs=6,\n",
        "                              max_concurrent_runs=4)\n",
        "\n",
        "experiment = Experiment(workspace = ws, name = 'hyperdrive_training')\n",
        "hyperdrive_run = experiment.submit(config=hyperdrive)"
      ],
      "metadata": {
        "id": "gfVGaKAKuBPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Monitoring and reviewing hyperdrive runs**"
      ],
      "metadata": {
        "id": "Y7I5Jc88uH0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for child_run in run.get_children():\n",
        "    print(child_run.id, child_run.get_metrics())"
      ],
      "metadata": {
        "id": "yJyRCWvKuBYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for child_run in hyperdrive_run.get_children_sorted_by_primary_metric():\n",
        "    print(child_run)"
      ],
      "metadata": {
        "id": "Eo5O9bS1uK1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_run = hyperdrive_run.get_best_run_by_primary_metric()"
      ],
      "metadata": {
        "id": "frc0PhHMuK38"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}